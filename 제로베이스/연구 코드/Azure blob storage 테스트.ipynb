{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b435f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import json\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c84dddd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aiohttp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8a630a4e9181>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mazure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBlobServiceClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\azure\\storage\\blob\\aio\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_models\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBlobType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicies_async\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExponentialRetry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearRetry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_blob_client_async\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBlobClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_container_client_async\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mContainerClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_blob_service_client_async\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBlobServiceClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\azure\\storage\\blob\\aio\\_blob_client_async.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_models\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBlobType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlobBlock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlobProperties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lease_async\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBlobLeaseClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_download_async\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStorageStreamDownloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\azure\\storage\\blob\\aio\\_download_async.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAsyncIterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0maiohttp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClientPayloadError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mazure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHttpResponseError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mServiceResponseError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencryption\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecrypt_blob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'aiohttp'"
     ]
    }
   ],
   "source": [
    "# a\n",
    "import asyncio\n",
    "from azure.storage.blob.aio import BlobServiceClient\n",
    "\n",
    "# d\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# f\n",
    "from functools import wraps\n",
    "from flask import jsonify, request\n",
    "\n",
    "# j\n",
    "import json\n",
    "\n",
    "# m\n",
    "from math import ceil, floor\n",
    "\n",
    "# n\n",
    "import numpy as np\n",
    "\n",
    "# o\n",
    "import os\n",
    "\n",
    "# p\n",
    "import pandas as pd\n",
    "\n",
    "# s\n",
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# u\n",
    "from urllib.parse import quote_plus\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "\n",
    "# Data path of Azure blob storage files\n",
    "data_parents_path = '/data/'\n",
    "\n",
    "# Azure SQL-Server(MS-SQL) config\n",
    "host = 'dms-bi-db-service.database.windows.net'\n",
    "port = '1433'\n",
    "db = 'site'\n",
    "user = 'lance'\n",
    "pwd = '[P@ssw0rd][P@ssw0rd]'\n",
    "\n",
    "# ODBC config\n",
    "odbc_driver = 'ODBC Driver 17 for SQL Server'\n",
    "odbc_url = f'DRIVER={odbc_driver};SERVER=tcp:{host},{port};DATABASE={db};UID={user};PWD={pwd}'\n",
    "odbc_url_qp = quote_plus(odbc_url)\n",
    "odbc_engine_url = f'mssql+pyodbc:///?odbc_connect={odbc_url_qp}'\n",
    "\n",
    "##### Helps Decorator\n",
    "def engine_manager(origin):\n",
    "    '''\n",
    "    # Function : Before origin(Create sqlalchemy engine) / After origin(Dispose sqlalchemy engine)\n",
    "    # Params : \n",
    "        1. origin : function\n",
    "    # Return : function\n",
    "    '''\n",
    "    @wraps(origin)\n",
    "    def _wrapper():\n",
    "        global odbc_engine_url\n",
    "        engine = create_engine(odbc_engine_url, fast_executemany=True, encoding='utf-8', pool_size=50, max_overflow=0)\n",
    "        conn = engine.connect()\n",
    "        trans = conn.begin()\n",
    "        result = origin(conn, trans)\n",
    "        conn.close()\n",
    "        engine.dispose()\n",
    "        return result\n",
    "    return _wrapper\n",
    "\n",
    "\n",
    "##### Helps Functions\n",
    "def set_scheam(conn_str):\n",
    "    return [ item.split('=')[1] for item in conn_str.split(';') if 'AccountName' in item ][0] \n",
    "\n",
    "def make_time_dirs(start_time:str, end_time:str):\n",
    "    '''\n",
    "    # Function : Make time directory list(range : start_time <= item <= end_time)\n",
    "    # Params :\n",
    "        1. start_time : str\n",
    "        2. end_time : str\n",
    "    # Return : list\n",
    "    '''\n",
    "    date_fmt = '%Y-%m-%d %H:00:00'\n",
    "    start_time = datetime.strptime(start_time, date_fmt)\n",
    "    end_time = datetime.strptime(end_time, date_fmt)\n",
    "\n",
    "    dir_fmt = '%Y/%m/%d/%H'\n",
    "    result = list()\n",
    "    sub_time = end_time - start_time\n",
    "    sub_sec = sub_time.total_seconds()\n",
    "    sub_hour = floor(sub_sec/3600)\n",
    "\n",
    "    for hour in range(0,sub_hour+1):\n",
    "        dir = (end_time - timedelta(hours=hour)).strftime(dir_fmt)\n",
    "        result.append(dir)  \n",
    "    return result\n",
    "\n",
    "\n",
    "async def stream_blob(params, time_dir, target):\n",
    "    '''\n",
    "    # Function : Asyncio execution, download 'blob client'\n",
    "    # Params :\n",
    "        1. form : werkzeug.local.LocalProxy\n",
    "        2. time_dir : str\n",
    "    # Return : str\n",
    "    '''\n",
    "    from azure.storage.blob.aio import BlobServiceClient\n",
    "    conn_str = params['conn_str']\n",
    "    container = params['container']\n",
    "    service = params['service']\n",
    "    myblob = os.path.join(service, time_dir, target)\n",
    "    \n",
    "    result = ''\n",
    "    try :\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(conn_str)\n",
    "        async with blob_service_client:\n",
    "            container_client = blob_service_client.get_container_client(container)\n",
    "            blob_client = container_client.get_blob_client(myblob)\n",
    "\n",
    "            if await blob_client.exists():\n",
    "                stream = await blob_client.download_blob()\n",
    "                data = await stream.readall()\n",
    "                result = data.decode('utf-8')\n",
    "\n",
    "            return result\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "async def stream_main(params):\n",
    "    '''\n",
    "    # Function : Asyncio execution main function for download 'blob client'\n",
    "    # Params :\n",
    "        1. form : werkzeug.local.LocalProxy\n",
    "    # Return : str\n",
    "    '''\n",
    "    start_time = params['start_time']\n",
    "    end_time = params['end_time']\n",
    "    time_dirs = make_time_dirs(start_time, end_time)\n",
    "\n",
    "    futures = []\n",
    "    for target in params['target']:\n",
    "        for time_dir in time_dirs:\n",
    "            futures.append(asyncio.ensure_future(stream_blob(params, time_dir, target))) \n",
    "    # futures  = [asyncio.ensure_future(stream_blob(params, time_dir)) for time_dir in time_dirs]\n",
    "    results = await asyncio.gather(*futures)\n",
    "\n",
    "    return ''.join(results)\n",
    "\n",
    "\n",
    "def make_df(params):\n",
    "    '''\n",
    "    # Function : Run stream_main function and Make dataframe\n",
    "    # Params :\n",
    "        1. form : werkzeug.local.LocalProxy\n",
    "    # Return : Dataframe\n",
    "    '''\n",
    "    result = None\n",
    "    data = asyncio.run(stream_main(params))\n",
    "    if data[:2]:\n",
    "        data = '[{0}]'.format(data.replace('\\n', ',')[:-1])\n",
    "        data_ls = list(map(lambda x : x['data'], json.loads(data)))\n",
    "        result = pd.json_normalize(data_ls)\n",
    "    return result\n",
    "\n",
    "def replace_to_sql(df_res, schema, table, query, conn, trans):\n",
    "    '''\n",
    "    # Function : Try : Drop table and create table. finally : Append to sql of pandas dataframe\n",
    "    # Params :\n",
    "        1. df_res : Pandas dataframe\n",
    "        2. schema : str\n",
    "        3. table : str\n",
    "        4. query : str\n",
    "        5. conn : sqlalchemy.engine.base.Connection\n",
    "        6. trans : sqlalchemy.engine.base.RootTransaction\n",
    "    # Return : str : Result message of Preprocessing \n",
    "    '''\n",
    "    try:\n",
    "        conn.execute(query)\n",
    "        df_res.to_sql(schema=schema, name=table, con=conn, if_exists='append',  index=False, index_label=None, chunksize=10000)\n",
    "        trans.commit()\n",
    "        result = {\"RESULT\":\"OK\"}\n",
    "    except Exception as e:\n",
    "        trans.rollback()\n",
    "        result = {\"RESULT\":\"ERROR\", \"MESSAGE\":str(e)}\n",
    "    return result\n",
    "\n",
    "\n",
    "def append_to_sql(df_res, schema, table, query, conn, trans, time_column='db_update_time' , hours=24):\n",
    "    '''\n",
    "    # Function : Try : Create table if not exists and append new dataframe. finally : Delete from table where db_update_time < now() - 24H\n",
    "    # Params :\n",
    "        1. df_res : Pandas dataframe\n",
    "        2. schema : str\n",
    "        3. table : str\n",
    "        4. query : str\n",
    "        5. conn : sqlalchemy.engine.base.Connection\n",
    "        6. trans : sqlalchemy.engine.base.RootTransaction\n",
    "        7. time_column : \n",
    "        7. hours : int() -> 24\n",
    "    # Return : str : Result message of Preprocessing \n",
    "    '''\n",
    "    try:\n",
    "        time_line = datetime.now() - timedelta(hours=hours)\n",
    "        time_line_str = time_line.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        conn.execute(query)\n",
    "        df_res.to_sql(schema=schema, name=table, con=conn, if_exists='append',  index=False, index_label=None, chunksize=10000)\n",
    "        conn.execute(\n",
    "            f\"\"\" DELETE FROM {schema}.{table} WHERE {time_column} < '{time_line_str}' \"\"\"\n",
    "        )\n",
    "        trans.commit()\n",
    "        result = {\"RESULT\":\"OK\"}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        trans.rollback()\n",
    "        result = {\"RESULT\":\"ERROR\", \"MESSAGE\":str(e)}\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabe41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stream_blob(params, time_dir, target):\n",
    "    '''\n",
    "    # Function : Asyncio execution, download 'blob client'\n",
    "    # Params :\n",
    "        1. form : werkzeug.local.LocalProxy\n",
    "        2. time_dir : str\n",
    "    # Return : str\n",
    "    '''\n",
    "    from azure.storage.blob.aio import BlobServiceClient\n",
    "    conn_str = params['conn_str']\n",
    "    container = params['container']\n",
    "    service = params['service']\n",
    "    myblob = os.path.join(service, time_dir, target)\n",
    "    \n",
    "    result = ''\n",
    "    try :\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(conn_str)\n",
    "        async with blob_service_client:\n",
    "            container_client = blob_service_client.get_container_client(container)\n",
    "            blob_client = container_client.get_blob_client(myblob)\n",
    "\n",
    "            if await blob_client.exists():\n",
    "                stream = await blob_client.download_blob()\n",
    "                data = await stream.readall()\n",
    "                result = data.decode('utf-8')\n",
    "\n",
    "            return result\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "async def stream_main(params):\n",
    "    '''\n",
    "    # Function : Asyncio execution main function for download 'blob client'\n",
    "    # Params :\n",
    "        1. form : werkzeug.local.LocalProxy\n",
    "    # Return : str\n",
    "    '''\n",
    "    start_time = params['start_time']\n",
    "    end_time = params['end_time']\n",
    "    time_dirs = make_time_dirs(start_time, end_time)\n",
    "\n",
    "    futures = []\n",
    "    for target in params['target']:\n",
    "        for time_dir in time_dirs:\n",
    "            futures.append(asyncio.ensure_future(stream_blob(params, time_dir, target))) \n",
    "    # futures  = [asyncio.ensure_future(stream_blob(params, time_dir)) for time_dir in time_dirs]\n",
    "    results = await asyncio.gather(*futures)\n",
    "\n",
    "    return ''.join(results)\n",
    "\n",
    "\n",
    "def make_df(params):\n",
    "    '''\n",
    "    # Function : Run stream_main function and Make dataframe\n",
    "    # Params :\n",
    "        1. form : werkzeug.local.LocalProxy\n",
    "    # Return : Dataframe\n",
    "    '''\n",
    "    result = None\n",
    "    data = asyncio.run(stream_main(params))\n",
    "    if data[:2]:\n",
    "        data = '[{0}]'.format(data.replace('\\n', ',')[:-1])\n",
    "        data_ls = list(map(lambda x : x['data'], json.loads(data)))\n",
    "        result = pd.json_normalize(data_ls)\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
